{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9816589e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.utils.data as data\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "device = torch.device('cuda')\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "\n",
    "train = pd.read_csv('./train.csv')\n",
    "labels=torch.from_numpy(np.array(train['label']))\n",
    "train.pop('label')#抛弃标签列\n",
    "ones = torch.sparse.torch.eye(10)\n",
    "#根据指定索引和维度保留单位矩阵中的一条数据即为one-hot编码\n",
    "label_one_hot=ones.index_select(0,labels)\n",
    "\n",
    "#还原图像，用卷积\n",
    "imgs=torch.from_numpy(np.array(train))\n",
    "imgs = imgs.to(torch.float32)\n",
    "imgs=imgs.view(42000,28,28)\n",
    "\n",
    "#归一化\n",
    "mean = torch.mean(imgs, dim=0)\n",
    "std = torch.std(imgs, dim=0)\n",
    "imgf= torch.div(torch.sub(imgs, mean), std)\n",
    "nan_mask = torch.isnan(imgf)\n",
    "imgf= torch.where(nan_mask, torch.zeros_like(imgf), imgf)\n",
    "imgf=torch.unsqueeze(imgf,1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#定义数据集\n",
    "\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, data, labels):\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # 从数据和标签中获取对应索引的数据和标签，并返回\n",
    "        data_item = self.data[index]\n",
    "        label_item = self.labels[index]\n",
    "        return data_item, label_item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "\n",
    "dataset = MyDataset(imgf, label_one_hot)\n",
    "train_size = int(0.8 * len(dataset))  # 训练集大小为数据集大小的 80%\n",
    "test_size = len(dataset) - train_size  # 测试集大小为数据集大小的 20%\n",
    "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "testlegth=len(test_dataset)\n",
    "trainleg=len(train_dataset)\n",
    "\n",
    "step=0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4a3da31f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "model(\n",
       "  (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "  (fc4): Linear(in_features=1600, out_features=512, bias=True)\n",
       "  (bn4): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (fc1): Linear(in_features=512, out_features=256, bias=True)\n",
       "  (bn1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (fc2): Linear(in_features=256, out_features=100, bias=True)\n",
       "  (bn2): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (fc3): Linear(in_features=100, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#模型\n",
    "class model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(model,self).__init__()\n",
    "        self.conv1=nn.Conv2d(1,32,kernel_size=3,padding=0,stride=1)\n",
    "        self.pool1=nn.MaxPool2d(2)\n",
    "        self.conv2=nn.Conv2d(32,64,kernel_size=3,padding=0,stride=1)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc4 = nn.Linear(1600, 512)  # 全连接层1\n",
    "        self.bn4 = nn.BatchNorm1d(512)  # 批标准化层1\n",
    "        self.fc1 = nn.Linear(512, 256)  # 全连接层1\n",
    "        self.bn1 = nn.BatchNorm1d(256)  # 批标准化层1\n",
    "        self.fc2 = nn.Linear(256, 100)  # 全连接层2\n",
    "        self.bn2 = nn.BatchNorm1d(100)  # 批标准化层2\n",
    "        self.fc3 = nn.Linear(100, 10)  # 全连接层2\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = self.pool1(F.relu(self.conv1(x)))\n",
    "        x = self.pool1(F.relu(self.conv2(x)))\n",
    "        x = self.flatten(x)  # 将特征图展平为一维向量\n",
    "        x = torch.relu(self.bn4(self.fc4(x)))  # 全连接层1 -> 批标准化层1 -> ReLU激活函数\n",
    "        x = torch.relu(self.bn1(self.fc1(x)))  # 全连接层1 -> 批标准化层1 -> ReLU激活函数\n",
    "        x = torch.relu(self.bn2(self.fc2(x)))  # 全连接层2 -> 批标准化层2 -> ReLU激活函数\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "net=model()\n",
    "net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "094814c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "经过这轮，训练集准确度为99.73213958740234%\n",
      "经过这轮，测试集准确度为：99.16666412353516%\n",
      "Net save successfully.\n"
     ]
    }
   ],
   "source": [
    "#超参数设置\n",
    "learning_rate=1e-6\n",
    "\n",
    "epoch=1\n",
    "\n",
    "\n",
    "# 损失函数\n",
    "loss = nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "# 优化器梯度下降\n",
    "optim = torch.optim.Adam(params=net.parameters(), lr=learning_rate)\n",
    "for i in range(0,epoch):\n",
    "    net.train()#表示模型开始训练模式，更新参数\n",
    "    true_num=0\n",
    "    for data in train_loader:\n",
    "        images, label = data\n",
    "        #移到gpu\n",
    "        images = images.to(device)\n",
    "        label = label.to(device)\n",
    "        outputs=net(images)\n",
    "\n",
    "        loss_results = loss(outputs, label)\n",
    "\n",
    "        optim.zero_grad()#optimizer.zero_grad()# 是 PyTorch 中定义优化器的一个方法，它会将模型中所有可训练的参数的梯度清零。在训练神经网络时，通常需要在每次迭代之前调用这个函数。因为如果不清零梯度，那么优化器在更新权重时会累加之前的梯度。\n",
    "\n",
    "        loss_results.backward()#optim.step()是PyTorch的一个方法，它根据反向传播过程中计算的梯度来更新优化器的参数。它通常在 loss.backward() 之后被调用，以更新模型的权重。\n",
    "        optim.step()\n",
    "        true_num += (outputs.argmax(1) == label.argmax(1)).sum()\n",
    "  \n",
    "    accuracy = true_num / trainleg\n",
    "    print(\"经过这轮，训练集准确度为{}%\".format(accuracy * 100))\n",
    "    #测试\n",
    "    net.eval()#停止参数修改\n",
    "    true=0\n",
    "    running_loss=0\n",
    "    with torch.no_grad():\n",
    "        for data in test_loader:\n",
    "            images, label=data\n",
    "            images = images.to(device)\n",
    "            label = label.to(device)\n",
    "\n",
    "            outputs = net(images)\n",
    "            results = (outputs.argmax(1) == label.argmax(1)).sum()\n",
    "            true += results\n",
    "            loss_results = loss(outputs, label)\n",
    "            running_loss += loss_results.item()\n",
    "    accuracy = true/testlegth\n",
    "\n",
    "    print(\"经过这轮，测试集准确度为：{}%\".format(accuracy*100))\n",
    "  \n",
    "    #可视化\n",
    "\n",
    "    torch.save(net, \"./Net_save/Net_save_{}.pth\".format(i))\n",
    "    print(\"Net save successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a4550724",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28000"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = pd.read_csv('./test.csv')\n",
    "\n",
    "device = torch.device('cuda')\n",
    "len(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "65163b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "#还原图像，用卷积\n",
    "img=torch.from_numpy(np.array(df_test))\n",
    "img = img.to(torch.float32)\n",
    "img=img.view(28000,28,28)\n",
    "\n",
    "#归一化\n",
    "mean = torch.mean(img, dim=0)\n",
    "std = torch.std(img, dim=0)\n",
    "imgf2= torch.div(torch.sub(img, mean), std)\n",
    "nan_mask = torch.isnan(imgf2)\n",
    "imgf2= torch.where(nan_mask, torch.zeros_like(imgf2), imgf2)\n",
    "imgf2=torch.unsqueeze(imgf2,1)\n",
    "\n",
    "\n",
    "#测试集预测部分\n",
    "net.eval()\n",
    "#传入GPU\n",
    "imgf2=imgf2.to('cpu')\n",
    "net=net.to('cpu')\n",
    "#计算结果\n",
    "_,pre=net(imgf2).max(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "cc0bcb91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2, 0, 9,  ..., 3, 9, 2])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0321aed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#将结果转为提交kaggle的格式\n",
    "res={}\n",
    "pre = pre.numpy()\n",
    "pre_size=pre.shape[0]\n",
    "num = [i for i in range(1,pre_size+1)]\n",
    "res_df=pd.DataFrame({\n",
    "    'ImageId':num,\n",
    "    'Label':pre\n",
    "})\n",
    "\n",
    "#d导出为CSV文件\n",
    "res_df.to_csv('res.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2840206",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.utils.data as data\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "%matplotlib inline\n",
    "\n",
    "#构造一个Pytorch数据迭代器\n",
    "def load_array(data_arrays,batch_size,is_train=True):\n",
    "    #加星号说明为元组\n",
    "    #TensorDataset 可以用来对 tensor 进行打包\n",
    "    dataset=data.TensorDataset(*data_arrays)\n",
    "    return data.DataLoader(dataset,batch_size,shuffle=is_train)\n",
    "train_data=load_array((imgs,label_one_hot), batch_size=32)\n",
    "\n",
    "\n",
    "\n",
    "#enumerate() 函数用于将一个可遍历的数据对象(如列表、元组或字符串)组合为一个索引序列，同时列出数据和数据下标，一般用在 for 循环当中。\n",
    "exaples=enumerate(train_data)\n",
    "#next() 返回迭代器的下一个项目\n",
    "batch_idx,(example_img,example_label) = next(exaples)\n",
    "fig=plt.figure()\n",
    "for i in range(32):\n",
    "    plt.subplot(16,2,i+1)\n",
    "    plt.subplots_adjust(wspace=0.3, hspace=10)\n",
    "    plt.imshow(example_img[i].reshape(28,28),cmap='gray',interpolation='none',extent=(-2, 2, -2, 2))\n",
    "    _,prd=example_label[i].max(0)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "138cc165",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
